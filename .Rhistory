```{r,eval=FALSE}
library("knitr", lib.loc="~/R/win-library/3.1")
knitr
knit
par(mar = rep(2.3, 4))
for (i in seq(pi/2, -4/3 * pi, length = 12)) {
plot(0, 0, pch = 20, ann = FALSE, axes = FALSE)
arrows(0, 0, cos(i), sin(i))
axis(1, 0, "6"); axis(2, 0, "9")
axis(3, 0, "12"); axis(4, 0, "3"); box()
}
for (i in seq(pi/2, -4/3 * pi, length = 12)) {
plot(0, 0, pch = 20, ann = FALSE, axes = FALSE)
arrows(0, 0, cos(i), sin(i))
axis(1, 0, "6"); axis(2, 0, "9")
axis(3, 0, "12"); axis(4, 0, "3"); box()
}
```{r,fig.width=4,fig.height=4,out.width='0.35\\linewidth',fig.show='animate'}
par(mar = rep(2.3, 4))
for (i in seq(pi/2, -4/3 * pi, length = 12)) {
plot(0, 0, pch = 20, ann = FALSE, axes = FALSE)
arrows(0, 0, cos(i), sin(i))
axis(1, 0, "6"); axis(2, 0, "9")
axis(3, 0, "12"); axis(4, 0, "3"); box()
}
```{r demo, prompt=TRUE}
a=1
```
plot(1)
par(mar = c(4, 4, 4, 4))
plot(1)
library(xlsx)
rm(list=ls())
setwd()
library(RCurl)
library(stringr)
temp=getURL("http://quote.eastmoney.com/stocklist.html",.encoding="GB2312")
getwd()
pattern="http://quote.eastmoney.com/"
library(XML)
detach("package:knitr", unload=TRUE)
library("knitr", lib.loc="~/R/win-library/3.1")
detach("package:knitr", unload=TRUE)
library(RCurl)
library(stringr)
library(XML)
temp=getURL("http://quote.eastmoney.com/stocklist.html",.encoding="GB2312")
pattern="http://quote.eastmoney.com/"
temp1=strsplit(x=temp,split =pattern )
names(temp1)
temp1=strsplit(x=temp,split =pattern )[[1]]
temp1
temp1[[1]]
temp2=temp1[grep(pattern = "</a></li>",  temp1)]
temp3=unlist(strsplit(temp2,"</a></li>"))
temp1=strsplit(x=temp,split =pattern )[[1]]
temp2=temp1[grep(pattern = "</a></li>",  temp1)]
temp3=unlist(strsplit(temp2,"</a></li>"))
tmp3
temp3
table=readHTMLTable(temp)
tmp=readLines(con = temp)
temp=getURL("http://quote.eastmoney.com/stocklist.html",.encoding="GB2312")
tmp=readLines(con = temp)
rm(list=ls())
#获取沪深股票的代码，用的是东方财富网的数据
## 加载包
library(RCurl)
library(stringr)
library(XML)
#网址
url=getURL("http://quote.eastmoney.com/stocklist.html",.encoding="GB2312")
url="http://quote.eastmoney.com/stocklist.html"
rawdat=getURL(url,.encoding="GB2312")
rawdat1=strsplit(x=rawdat,split =pattern )
pattern="http://quote.eastmoney.com/"
rawdat1=strsplit(x=rawdat,split =pattern )[[1]]
rawdat1[[1]]
rawdat1[[2500]]
grep(pattern = "</a></li>",  rawdat1)
grepl(pattern = "</a></li>",  rawdat1)
tmp=rawdat1[grepl(pattern = "</a></li>",  tmp)]
tmp=strsplit(x=rawdat,split =pattern )[[1]]
tmp=rawdat1[grepl(pattern = "</a></li>",  tmp)]
tmp[2500]
tmp=unlist(strsplit(tmp,"</a></li>"))
tmp[1]
tmp[2500]
tmp[2501]
gc()
library("WindR", lib.loc="~/R/win-library/3.1")
w.start()
library("XML", lib.loc="~/R/win-library/3.1")
rm(list=ls())
library(kintr)
opts_chunk$set(comment=NA, fig.width=6, fig.height=6,cache = TRUE)
library(knitr)
opts_chunk$set(comment=NA, fig.width=6, fig.height=6,cache = TRUE)
library(XML)
library(kintr)
library(knitr)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
fileUrl <- "http://www.w3school.com.cn/example/xmle/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
doc
rootNode <- xmlRoot(doc) #XML节点
names(rootNode)
xmlName(rootNode)
rootNode[[1]]
rootNode[[1]][[1]]
rootNode[[1]][[2]]
rootNOde[[2]]
xpathSApply(rootNode,"/food",xmlValue)  #顶层节点
xpathSApply(rootNode,"//name",xmlValue) #次一层节点
xpathSApply(rootNode,food[@name],xmlValue) #次一层节点
xpathSApply(rootNode,food[@attr-name="name"],xmlValue) #次一层节点
xpathSApply(rootNode,food[name],xmlValue) #次一层节点
xpathSApply(rootNode,"food[name]",xmlValue) #次一层节点
xpathSApply(rootNode,"food[attr-name="name"]",xmlValue) #次一层节点
xpathSApply(rootNode,"food[attr-name='name']",xmlValue) #次一层节点
rm(list=ls())
library(XML)
fileUrl <- "http://quote.eastmoney.com/stocklist.html"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
doc <- xmlTreeParse(fileUrl,useInternal=TRUE,encoding = "GBK")
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE,encoding = "GBK")
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE)
xpathSApply(doc,"//li[@class='score']",xmlValue)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue)
teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)
scores
teams
fileUrl <- "http://www.w3school.com.cn/example/xmle/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE)
xpathSApply(doc,"food[@class]",xmlValue) #次一层节点
xpathSApply(doc,"food[@class="name"]",xmlValue) #对文档操作而不是节点文档，次一层节点
xpathSApply(doc,"//food[@class]",xmlValue) #次一层节点
xpathSApply(doc,"//food[@class='name']",xmlValue)
xpathSApply(doc,"//food[@class='price']",xmlValue) #对文档操作而不是节点文档，次一层节点
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue) #对文档操作，而不是节点文件
teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)
scores
teams
library(XML)
library(RCurl)
url1="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData <- getURL(url1) #载入数据
url="http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData <- getURL(url) #Changing https to http also seems to work.
doc=xmlTreeParse( file = xData,useInternal=TRUE)
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE,encoding = "GBK")
rootnode=xmlRoot(doc)
li=xpathSApply(doc,"//li",xmlValue)
li[[2300]]
li[[2000]]
li
li_vec=unlist(li)
li_vec
read.csv( li_vec,header = F,sep = " ","stockname.csv")
write.csv( li_vec,"stockname.csv",header = F,sep = " ")
write.csv( li_vec,"stockname.csv")
library(stringr)
stri_enc_detect(li)  #检测文档编码
install.packages("stringi")
library(stringi)
enc=stri_enc_detect(li)  #检测文档编码
enc
enc=stri_enc_detect(li_vec)
enc
write.csv( li_vec,"stockname.csv",fileEncoding="GBK")
library(XML)
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE,encoding = "UTF-8")
rootnode=xmlRoot(doc)
li=xpathSApply(doc,"//li",xmlValue) #发现读取回来的文字是乱码
li_vec=unlist(li)
li
doc <- htmlTreeParse(fileUrl,useInternal=TRUE,encoding = "GBK")
iconv(x = doc,from = "GBK",to = "UTF-8")
rm(list=ls())
library(XML)
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE,encoding = "GBK")
iconv(x = doc,from = "GBK",to = "UTF-8")
rootnode=xmlRoot(doc)
li=xpathSApply(doc,"//li",xmlValue) #发现读取回来的文字是乱码
li_vec=unlist(li)
iconv(x = li_vec,from = "GBK",to = "UTF-8")
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc=getURL(url = fileUrl,.encoding = "GBK")
class(doc)
doc=iconv(x = doc,from = "GBK",to = "UTF-8")
rootnode=xmlRoot(doc) #直接取节点
methods(xmlRoot)
url="http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData <- getURL(url) #Changing https to http also seems to work.
class(xData)
doc=xmlTreeParse( file = xData,useInternal=TRUE)
rm(list=ls())
library(XML)
library(RCurl)
url="http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData <- getURL(url) #Changing https to http also seems to work.
doc=xmlTreeParse( file = xData,useInternal=TRUE)
doc=xmlTreeParse(file = doc,useInternalNodes = T)
library(XML)
library(RCurl)
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc=getURL(url = fileUrl,.encoding = "GBK")
class(doc) #发现doc是字符串，可以使用iconv函数转换成UTF-8格式
doc=iconv(x = doc,from = "GBK",to = "UTF-8")
doc=xmlTreeParse(file = doc,useInternalNodes = T)
rm(list=ls())
library(XML)
library(RCurl)
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc=getURL(url = fileUrl,.encoding = "GBK")
class(doc) #发现doc是字符串，可以使用iconv函数转换成UTF-8格式
doc=iconv(x = doc,from = "GBK",to = "UTF-8")
doc=xmlTreeParse(file = doc,useInternalNodes = T) #报错，标签不匹配等
rootnode=xmlRoot(doc) #直接取节点,因为doc是字符串不可行
install.packages("jsonlite")
rm(list=ls())
library(knitr)
library(jsonlite)
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
class(jsonData)
names(jsonData)
names(jsonData)
names(jsonData$owner)
jsonData$owner$login
myjson <- toJSON(iris, pretty=TRUE)
cat(myjson)
iris2 <- fromJSON(myjson)
print(iris2)
cat(myjson)[1]
cat(myjson)[[1]]
library(pryr)
library("pryr", lib.loc="~/R/win-library/3.1")
install.packages("Rcpp")
library(pryr)
otype(jsonData)
fattern(jsonData)
flatten(jsonData)
class(flatten(jsonData))
df=flatten(jsonData)
str(df)
which(names(df)=="repos_url")
which(names(jsonData)=="repos_url",arr.ind = T)
names(jsonData)
which(names(df)=="html_url")
which(names(df)=="html_url",arr.ind = T)
which(names(jsonData)=="html_url",arr.ind = T)
names(df)
names(jsonData)
names(jsonData)
names(jsonData$owner)
jsonData["owner",]
jsonData$owner
class(jsonData$owner)
str(jsonData$owner)
clear
cl()
clear()
install.packages("data.tree")
install.packages("data.table")
library(data.table)
df=data.frame(a=sample(c(1:10),size = 20,replace = T),b=sample(letters[1:10],20,T))
#新建dt
dt=data.table(a=sample(c(1:10),size = 20,replace = T),b=sample(letters[1:10],20,T))
dt2=as.data.table(x = df)
head(dt)
dt[3,]
dt[,1]
dt["a"]
methods([)
methods(plot)
methods([])
methods("[")
getS3method(f = "[",class = "data.table")
dt[,list(mean(a),length(b))]
dt[,table(b)]
dt2=dt
head(dt)
dt2[1,1]=30
head(dt) #dt发生变化
dt[1,1]=100
head(dt2)
dt[1,1]
dt2=dt
head(dt)
dt2[1,]=c(30,"x")
head(dt) #dt发生变化
install.packages("quantmod")
install.packages("jpeg")
