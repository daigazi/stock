---
title: "XML"
author: "daigazi"
date: "2015年11月4日"
output: html_document
---

```{r,echo=F}
library(knitr)
opts_chunk$set(comment=NA, fig.width=6, fig.height=6,cache = TRUE)
```

# XML

```{r,XMLl,eval=T,echo=TRUE,highlight=TRUE}
library(XML)
fileUrl <- "http://www.w3school.com.cn/example/xmle/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE) 
rootNode <- xmlRoot(doc) #得到XML节点
xmlName(rootNode) 
names(rootNode) 
rootNode[[1]]  #第一个names(rootNOde)标签里<food>的东西
rootNode[[1]][[1]] #标签内第一行
rootNode[[1]][[2]] #第二行
rootNode[[2]]
xmlSApply(X = rootNode,FUN = xmlValue) #对XML节点，利用xmlValue递归遍历整个文本，取标签里的值，最后用$连接各个值
#X          the XMLNode on whose children the regular apply or sapply is to be performed
#FUN        the function to apply to each child node. This is passed directly to the relevant apply function.

#...	additional arguments to be given to each invocation of FUN. This is passed directly to the relevant apply function.

```

# XPath
* /node Top level node
* //node Node at any level
* node[@attr-name] Node with an attribute name
* node[@attr-name='bob'] Node with attribute name attr-name='bob'
* Information from: [linked phrase](http://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf)
```{r,Xpath,eval=T,echo=TRUE,highlight=TRUE}
library(XML)
fileUrl <- "http://www.w3school.com.cn/example/xmle/simple.xml"
doc <- xmlTreeParse(fileUrl,useInternal=TRUE) 
rootNode <- xmlRoot(doc) #得到XML节点
xpathSApply(rootNode,"/food",xmlValue)  #顶层节点
xpathSApply(rootNode,"//name",xmlValue) #次一层节点
xpathSApply(rootNode,"//price",xmlValue) #次一层节点
xpathSApply(doc,"//food[@class='price']",xmlValue) #对文档操作而不是节点文档，次一层节点,为什么返回的是空列表
xpathSApply(doc,"//food[@class]",xmlValue) #次一层节点
```
这是因为此网页里food标签下无class属性，[此链接](http://my.oschina.net/u/1431368/blog/305311)所示的，就可以用。若上述网页里是<food class="12">noddle </food>这个形式，那么就xpathSApply(doc,"//food[@class]",xmlValue) 就可以取到"noodle"
```{r}
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE)
scores <- xpathSApply(doc,"//li[@class='score']",xmlValue) #对文档操作，而不是节点文件
teams <- xpathSApply(doc,"//li[@class='team-name']",xmlValue)
scores
teams
```

# XPath如东方财富网
利用xpathSApply函数读入东方财富网的股票信息
```{r,eval=F,echo=T,highlight=TRUE,error=TRUE}
library(XML)
fileUrl <- "http://quote.eastmoney.com/stocklist.html" 
doc <- htmlTreeParse(fileUrl,useInternal=TRUE,encoding = "GBK") #报错，这个网站出现nbsp（不间断间隔）、开始和结束标签不匹配等问题
rootNode <- xmlRoot(doc) #得到XML节点
xmlName(rootNode) 
names(rootNode) 
```

# XPath读取同花顺网页数据
利用xpathSApply函数读入同花顺股票信息

```{r,eval=F,echo=T,highlight=TRUE,error=TRUE}
library(XML)
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc <- htmlTreeParse(fileUrl,useInternal=TRUE,encoding = "GBK")  #注意是htmlTreeParse
rootnode=xmlRoot(doc)
li=xpathSApply(doc,"//li",xmlValue) #发现读取回来的文字是乱码
li_vec=unlist(li)
li_vec=iconv(x = li_vec,from = "gbk",to = "UTF-8") #x 字符串向量，还是乱码
# library(stringi)
# enc=stri_enc_detect(li_vec)  #检测文档编码
# li_vecstri_encode(li_vec,enc,"UTF-8")  #把文档转换成UTF-8格式
write.csv( li_vec,"stockname.csv",fileEncoding="GBK")
```
使用Rcurl::getUrl读入数据后再用htmlTreeParse分析，重点是在读入数据的时候把数据类型转换

```{r,error=TRUE}
library(XML)
library(RCurl)
fileUrl <- "http://bbs.10jqka.com.cn/codelist.html"
doc=getURL(url = fileUrl,.encoding = "GBK")
class(doc) #发现doc是字符串，可以使用iconv函数转换成UTF-8格式
doc=iconv(x = doc,from = "GBK",to = "UTF-8")
doc=xmlTreeParse(file = doc,useInternalNodes = T) #报错，标签不匹配等
rootnode=xmlRoot(doc) #直接取节点,因为doc是字符串不可行
#查看xmlRoot的方法，可以发现没有xmlRoot.character这个方法

```

```{r,error=TRUE}
library(XML)
library(RCurl)
url="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData=xmlTreeParse( file = url,useInternal=TRUE) #报错
#把url的https改成http就可以了
url1="http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc=xmlTreeParse( file = url1,useInternal=TRUE)  
rootnode=xmlRoot(doc)
zipcode=xpathSApply(doc,"//zipcode",xmlValue)
class(zipcode);typeof(zipcode)
zipcode[zipcode=="21231"]
```

## 另一种方式
```{r,error=TRUE}
library(XML)
library(RCurl)
url1="https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData <- getURL(url1) #载入数据
url="http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
xData <- getURL(url) #Changing https to http also seems to work.
doc=xmlTreeParse( file = xData,useInternal=TRUE) #报错，这个网站出现nbsp（不间断间隔）、开始和结束标签不匹配等问题
rootnode=xmlRoot(doc)
zipcode=xpathSApply(doc,"//zipcode",xmlValue)
class(zipcode);typeof(zipcode)
zipcode[zipcode==21231,]

```

## xml包几个常用的函数（可以在xpathSApply中应用）

```{r}
fileurl <- "http://www.w3school.com.cn/example/xmle/simple.xml"
web=xmlTreeParse(file = fileurl,trim = T,useInternal=TRUE,encoding = "GBK")
  #html网页用htmlTreeParse,xml用xmlTreeParse
node=xmlRoot(web) #获取高水平的XML节点
xmlName(node)  #获取顶层标签名
xmlAttrs(node)
```
 
### XML按层次取值
```{r}
 fileName <- system.file("exampleData", "mtcars.xml", package="XML") 
  doc <- xmlTreeParse(fileName)
  node=xmlRoot(doc)  #做标签树
  xmlName(node)  #顶层标签<dataset>
  xmlAttrs(node) #顶层标签<dataset>里的值，在<dataset name="mtcars" numRecords="32" source="R Project">中返回字符串 "mtcars"        "32" "R Project" 
  xmlGetAttr(node=node,name="numRecords")  #提取某个子属性的属性值
  xmlChildren(node)  #次一层标签
  xmlSize(xmlChildren(node))  #list的长度
  xmlChildren(node)[[1]]  #次一层标签的第一个子标签
  tmp=xmlChildren(node)[[20]]  #次一层标签的第20个子标签
  xmlGetAttr(tmp,"id")  #属性id的值
  xmlValue(tmp)  #值
  xmlSize(tmp)  #list的长度
  xmlChildren(xmlChildren(node)[[1]])  #次次层标签


```
### XML按标签取值
* /node 顶层标签
* //node 任意层标签
* node[@attr-name] 取节点下某个属性的
* node[@attr-name='bob'] 取节点下某个属性等于bob的值
```{r}
 fileName <- system.file("exampleData", "mtcars.xml", package="XML") 
  doc <- xmlTreeParse(fileName)
  node=xmlRoot(doc)
  getNodeSet(doc = node,path = "/dataset")
  getNodeSet(doc = node,path = "/dataset//record")
  getNodeSet(doc = node,path = "//record")
  getNodeSet(doc = node,path = "//variable") #可以直接取第三层的
  getNodeSet(doc = node,path = "/dataset//record[@id]")
  getNodeSet(doc = node,path = "/dataset//record[@id='Lotus Europa']")
```
